# -*- coding: utf-8 -*-
"""GAN_basic.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18UZrxY1RoQD7wmSNitxb8hdeU24OSduP
"""

import tensorflow.compat.v1 as tf
import numpy as np
import matplotlib.pyplot as plt
mnist = tf.keras.datasets.mnist
tf.compat.v1.disable_eager_execution()
x, y = mnist.load_data()

plt.imshow(x[0][0])



#have two dense layers
#varibale_cope is used because we have two models generator discriminator so , a prefix added to each layer of models . so , we can share layers ,models having same name by the scope name.
def generator_network(z,reuse=None):
  with tf.variable_scope('gen', reuse=reuse):

    l1=tf.layers.dense(inputs=z,units=128,activation=tf.nn.leaky_relu)
    l2=tf.layers.dense(inputs=l1,units=128,activation=tf.nn.leaky_relu)
    out=tf.layers.dense(inputs=l2,units=784,activation=tf.nn.tanh)
    return out
def discriminator_network(z,reuse=None):
  with tf.variable_scope('dis',reuse=reuse):
    l1=tf.layers.dense(inputs=z,units=128,activation=tf.nn.leaky_relu)
    l2=tf.layers.dense(inputs=l1,units=128,activation=tf.nn.leaky_relu)
    out=tf.layers.dense(inputs=l2,units=1)
    sig=tf.nn.sigmoid(out)
    return out,sig

#input 
tf.reset_default_graph()
real_image=tf.placeholder(tf.float32,shape=[None,784])#place holder is for passing the input 
Not_real=tf.placeholder(tf.float32,shape=[None,100])

generator_out=generator_network(Not_real)
#for discriminator network first we want to train in real images then we need to reuse the same model tp predict the model whether the output is real or not
dis_real,dis_real_sig=discriminator_network(real_image)
#for predicting
dis_notreal,dis_notreal_sig=discriminator_network(generator_out,reuse=True)

#loss
def loss_func(logits_in,labels_in):
    return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits_in,labels=labels_in))

D_real_loss=loss_func(dis_real,tf.ones_like(dis_real)*0.9) #Smoothing for generalization
D_fake_loss=loss_func(dis_notreal,tf.zeros_like(dis_real))
D_loss=D_real_loss+D_fake_loss

G_loss= loss_func(dis_notreal,tf.ones_like(dis_notreal))

learning_rate=.001
tvars=tf.trainable_variables()  #returns all variables created(the two variable scopes) and makes trainable true
d_vars=[var for var in tvars if 'dis' in var.name]
g_vars=[var for var in tvars if 'gen' in var.name]
D_trainer=tf.train.AdamOptimizer(learning_rate).minimize(D_loss,var_list=d_vars)
G_trainer=tf.train.AdamOptimizer(learning_rate).minimize(G_loss,var_list=g_vars)
batch_size=100

init=tf.global_variables_initializer()

epochs=100
samples=[] #generator examples

with tf.Session() as sess:
    sess.run(init)
    for epoch in range(epochs):
        num_batches=len(x[0])//batch_size

        print(x[0].shape)
        for i in range(len(x[0])):
            batch=x[0][i]
            image=batch.reshape(-1,784)
            image=image*2-1
            batch_z=np.random.uniform(-1,1,size=(1,100))
            _=sess.run(D_trainer,feed_dict={real_image:batch_images,Not_real:batch_z})
            _=sess.run(G_trainer,feed_dict={Not_real:batch_z})
            
        print("on epoch{}".format(epoch))
        
        sample_z=np.random.uniform(-1,1,size=(1,100))
        gen_sample=sess.run(generator_network(Not_real,reuse=True),feed_dict={Not_real:sample_z})
        
        samples.append(gen_sample)

plt.imshow(samples[0].reshape(28,28))

plt.imshow(samples[9].reshape(28,28))